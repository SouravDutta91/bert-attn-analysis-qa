# Analysis of Attention in BERT for QA Explainability
We are using the SQuAD 2.0 datast for this task.

## Dependencies

`pip install pytorch-pretrained-bert`

## Model

https://drive.google.com/file/d/1hktnjAJOdOwPxTK3R-KST9-kUQFYPusM/view?usp=sharing

## Run the script

`cd Code`

`python Test_Batch.py --paragraph ../Input_file.txt --model ../pytorch_model.bin --config_file ../Results/bert_config.json`
